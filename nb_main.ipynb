{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"./IntoThinAirBook.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# Cut out the open and closing parts\n",
    "pages = pages[26:277]\n",
    "\n",
    "# Combine the pages, and replace the tabs with spaces\n",
    "text = \"\"\n",
    "\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "    \n",
    "text = text.replace('\\t', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book has 131710 tokens in it\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"This book has {num_tokens} tokens in it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Splitters\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Embedding Support\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Summarizer we'll use for Map Reduce\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\t\"], chunk_size=10000, chunk_overlap=3000)\n",
    "\n",
    "docs = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now our book is split up into 78 documents\n"
     ]
    }
   ],
   "source": [
    "num_documents = len(docs)\n",
    "\n",
    "print (f\"Now our book is split up into {num_documents} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huke/openai-learning/venv2405/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "vectors = embeddings.embed_documents([x.page_content for x in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 11\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10,  5, 10, 10,  4,  4,  6,  8,  8,  8,  8,  4,  4,  4,  4,\n",
       "        3,  4,  5,  5,  5,  6,  6,  0,  4,  3,  3,  0,  0,  3,  6,  0,  7,\n",
       "        8,  6,  7,  7,  7,  7,  7,  1,  1,  7,  7,  7,  1,  7,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  7,  3,  1,  7,  7,  3,  3,  3,  3,\n",
       "        3,  3,  2,  2,  9,  9,  9,  9,  9,  9], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform t-SNE and reduce to 2 dimensions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m reduced_data_tsne \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Plot the reduced data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(reduced_data_tsne[:, \u001b[38;5;241m0\u001b[39m], reduced_data_tsne[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39mkmeans\u001b[38;5;241m.\u001b[39mlabels_)\n",
      "File \u001b[0;32m~/openai-learning/venv2405/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/openai-learning/venv2405/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/openai-learning/venv2405/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:1135\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[39m@_fit_context\u001b[39m(\n\u001b[1;32m   1111\u001b[0m     \u001b[39m# TSNE.metric is not validated yet\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m     prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m )\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \n\u001b[1;32m   1117\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[1;32m   1136\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[1;32m   1137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/openai-learning/venv2405/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:845\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 845\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    846\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Taking out the warnings\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "\n",
    "# Filter out FutureWarnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Perform t-SNE and reduce to 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_data_tsne = tsne.fit_transform(vectors)\n",
    "\n",
    "# Plot the reduced data\n",
    "plt.scatter(reduced_data_tsne[:, 0], reduced_data_tsne[:, 1], c=kmeans.labels_)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Book Embeddings Clustered')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "973d40b2b159501a25714dfd9efcd538724ccd5db5f6d4a830e5916e0fa69d6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
