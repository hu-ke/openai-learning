{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredEPubLoader\n",
    "\n",
    "def load_book(file_obj, file_extension):\n",
    "    \"\"\"Load the content of a book based on its file type.\"\"\"\n",
    "    text = \"\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:\n",
    "        temp_file.write(file_obj.read())\n",
    "        if file_extension == \".pdf\":\n",
    "            loader = PyPDFLoader(temp_file.name)\n",
    "            pages = loader.load()\n",
    "            text = \"\".join(page.page_content for page in pages)\n",
    "        elif file_extension == \".epub\":\n",
    "            loader = UnstructuredEPubLoader(temp_file.name)\n",
    "            data = loader.load()\n",
    "            text = \"\\n\".join(element.page_content for element in data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {file_extension}\")\n",
    "        os.remove(temp_file.name)\n",
    "    text = text.replace('\\t', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "def split_and_embed(text, openai_api_key):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\t\"], chunk_size=10000, chunk_overlap=3000)\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    vectors = embeddings.embed_documents([x.page_content for x in docs])\n",
    "    return docs, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def cluster_embeddings(vectors, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)\n",
    "    closest_indices = [np.argmin(np.linalg.norm(vectors - center, axis=1)) for center in kmeans.cluster_centers_]\n",
    "    return sorted(closest_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def summarize_chunks(docs, selected_indices, openai_api_key):\n",
    "    llm3_turbo = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, max_tokens=1000, model='gpt-3.5-turbo-16k')\n",
    "    map_prompt = \"\"\"\n",
    "    You are provided with a passage from a book. Your task is to produce a comprehensive summary of this passage. Ensure accuracy and avoid adding any interpretations or extra details not present in the original text. The summary should be at least three paragraphs long and fully capture the essence of the passage.\n",
    "    ```{text}```\n",
    "    SUMMARY:\n",
    "    \"\"\"\n",
    "    map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
    "    selected_docs = [docs[i] for i in selected_indices]\n",
    "    summary_list = []\n",
    "\n",
    "    for doc in selected_docs:\n",
    "        chunk_summary = load_summarize_chain(llm=llm3_turbo, chain_type=\"stuff\", prompt=map_prompt_template).run([doc])\n",
    "        summary_list.append(chunk_summary)\n",
    "    \n",
    "    return \"\\n\".join(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def create_final_summary(summaries, openai_api_key):\n",
    "    llm4 = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, max_tokens=3000, model='gpt-4', request_timeout=120)\n",
    "    combine_prompt = \"\"\"\n",
    "    You are given a series of summarized sections from a book. Your task is to weave these summaries into a single, cohesive, and verbose summary. The reader should be able to understand the main events or points of the book from your summary. Ensure you retain the accuracy of the content and present it in a clear and engaging manner.\n",
    "    ```{text}```\n",
    "    COHESIVE SUMMARY:\n",
    "    \"\"\"\n",
    "    combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])\n",
    "    reduce_chain = load_summarize_chain(llm=llm4, chain_type=\"stuff\", prompt=combine_prompt_template)\n",
    "    final_summary = reduce_chain.run([Document(page_content=summaries)])\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(uploaded_file, openai_api_key, num_clusters=11, verbose=False):\n",
    "    file_extension = os.path.splitext(uploaded_file.name)[1].lower()\n",
    "    text = load_book(uploaded_file, file_extension)\n",
    "    docs, vectors = split_and_embed(text, openai_api_key)\n",
    "    selected_indices = cluster_embeddings(vectors, num_clusters)\n",
    "    summaries = summarize_chunks(docs, selected_indices, openai_api_key)\n",
    "    final_summary = create_final_summary(summaries, openai_api_key)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the summarizer\n",
    "if __name__ == '__main__':\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    book_path = \"./charlie-and-the-chocolate-factory-by-roald-dahl.pdf\"\n",
    "    with open(book_path, 'rb') as uploaded_file:\n",
    "        summary = generate_summary(uploaded_file, openai_api_key, verbose=True)\n",
    "        print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "973d40b2b159501a25714dfd9efcd538724ccd5db5f6d4a830e5916e0fa69d6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
