{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredEPubLoader\n",
    "\n",
    "def load_book(file_obj, file_extension):\n",
    "    \"\"\"Load the content of a book based on its file type.\"\"\"\n",
    "    text = \"\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:\n",
    "        temp_file.write(file_obj.read())\n",
    "        if file_extension == \".pdf\":\n",
    "            loader = PyPDFLoader(temp_file.name)\n",
    "            pages = loader.load()\n",
    "            text = \"\".join(page.page_content for page in pages)\n",
    "        elif file_extension == \".epub\":\n",
    "            loader = UnstructuredEPubLoader(temp_file.name)\n",
    "            data = loader.load()\n",
    "            text = \"\\n\".join(element.page_content for element in data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {file_extension}\")\n",
    "        os.remove(temp_file.name)\n",
    "    text = text.replace('\\t', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "def split_and_embed(text, openai_api_key):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\t\"], chunk_size=10000, chunk_overlap=3000)\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    vectors = embeddings.embed_documents([x.page_content for x in docs])\n",
    "    return docs, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def cluster_embeddings(vectors, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)\n",
    "    closest_indices = [np.argmin(np.linalg.norm(vectors - center, axis=1)) for center in kmeans.cluster_centers_]\n",
    "    return sorted(closest_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def summarize_chunks(docs, selected_indices, openai_api_key):\n",
    "    llm3_turbo = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, max_tokens=1000, model='gpt-3.5-turbo-16k')\n",
    "    map_prompt = \"\"\"\n",
    "    You are provided with a passage from a book. Your task is to produce a comprehensive summary of this passage. Ensure accuracy and avoid adding any interpretations or extra details not present in the original text. The summary should be at least three paragraphs long and fully capture the essence of the passage.\n",
    "    ```{text}```\n",
    "    SUMMARY:\n",
    "    \"\"\"\n",
    "    map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
    "    selected_docs = [docs[i] for i in selected_indices]\n",
    "    summary_list = []\n",
    "\n",
    "    for doc in selected_docs:\n",
    "        chunk_summary = load_summarize_chain(llm=llm3_turbo, chain_type=\"stuff\", prompt=map_prompt_template).run([doc])\n",
    "        summary_list.append(chunk_summary)\n",
    "    \n",
    "    return \"\\n\".join(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def create_final_summary(summaries, openai_api_key):\n",
    "    llm4 = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, max_tokens=3000, model='gpt-4', request_timeout=120)\n",
    "    combine_prompt = \"\"\"\n",
    "    You are given a series of summarized sections from a book. Your task is to weave these summaries into a single, cohesive, and verbose summary. The reader should be able to understand the main events or points of the book from your summary. Ensure you retain the accuracy of the content and present it in a clear and engaging manner.\n",
    "    ```{text}```\n",
    "    COHESIVE SUMMARY:\n",
    "    \"\"\"\n",
    "    combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])\n",
    "    reduce_chain = load_summarize_chain(llm=llm4, chain_type=\"stuff\", prompt=combine_prompt_template)\n",
    "    final_summary = reduce_chain.run([Document(page_content=summaries)])\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(uploaded_file, openai_api_key, num_clusters=11, verbose=False):\n",
    "    file_extension = os.path.splitext(uploaded_file.name)[1].lower()\n",
    "    text = load_book(uploaded_file, file_extension)\n",
    "    docs, vectors = split_and_embed(text, openai_api_key)\n",
    "    selected_indices = cluster_embeddings(vectors, num_clusters)\n",
    "    summaries = summarize_chunks(docs, selected_indices, openai_api_key)\n",
    "    final_summary = create_final_summary(summaries, openai_api_key)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huke/openai-learning/venv2405/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/huke/openai-learning/venv2405/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book begins with the author, an experienced mountaineer, embarking on a journey to climb Mount Everest. Despite being in a different stage of life, with a stable career and family, the author's childhood dream of conquering Everest still lingers. He accepts an invitation to join Rob Hall's Everest expedition, and they fly to Kathmandu, where they meet the rest of the team. The author is immediately drawn to Hall's charismatic personality and is eager to begin the expedition under his guidance.\n",
      "\n",
      "The team begins their ascent, establishing a series of camps at increasing altitudes to acclimatize. They face numerous challenges, including navigating the treacherous Khumbu Icefall and enduring extreme weather conditions. Among the climbers is Sandy Pittman, a socialite who brings along her favorite coffee blend and press clippings about herself. Despite criticism from some climbers, Pittman's teammates appreciate her positive attitude and contributions to the expedition.\n",
      "\n",
      "As they continue their ascent, the author reflects on the history of Mount Everest, from its discovery in 1852 by Radhanath Sikhdar to the first successful summit in 1953. The author also highlights the significance of Everest as a coveted goal for mountaineers and the immense mass and imposing presence of the mountain itself.\n",
      "\n",
      "The climbers face numerous challenges during their ascent and descent, including exhaustion, low visibility, and hypothermia. They encounter fellow climbers in distress and must make difficult decisions to ensure their survival. Despite these challenges, the author and his team are determined to reach the summit.\n",
      "\n",
      "However, the expedition takes a tragic turn when a storm hits, causing several climbers to become disoriented and lost. Some climbers run out of oxygen, and others succumb to the harsh weather conditions. The author and his team huddle together, hoping for a break in the storm and a chance to find their way back to safety.\n",
      "\n",
      "In the aftermath of the storm, the author and his team face the devastating reality of their situation. Several climbers, including Rob Hall and Doug Hansen, are missing or presumed dead. The author feels a deep sense of guilt and impotence in the face of the families' grief upon their return to the United States.\n",
      "\n",
      "The author also addresses the criticism he received from Anatoli Boukreev, a fellow climber, regarding his account of the events on Everest. The author defends his integrity as a journalist and criticizes Boukreev's spokesperson for spreading allegations without fact-checking them. Despite their disagreements, the author expresses regret over Boukreev's untimely death during an expedition on Annapurna I.\n",
      "\n",
      "The book concludes with the author reflecting on the tragedy on Mount Everest and the lingering questions surrounding the events. Despite the risks and challenges, the author acknowledges the allure of Everest and the enduring desire of mountaineers to conquer the world's highest peak.\n"
     ]
    }
   ],
   "source": [
    "# Testing the summarizer\n",
    "if __name__ == '__main__':\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    book_path = \"./IntoThinAirBook.pdf\"\n",
    "    with open(book_path, 'rb') as uploaded_file:\n",
    "        summary = generate_summary(uploaded_file, openai_api_key, verbose=True)\n",
    "        print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "973d40b2b159501a25714dfd9efcd538724ccd5db5f6d4a830e5916e0fa69d6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
